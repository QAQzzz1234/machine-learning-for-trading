{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll compare the following storage formats:\n",
    "- CSV: Comma-separated, standard flat text file format.\n",
    "- HDF5: Hierarchical data format, developed initially at the National Center for Supercomputing Applications. It is a fast and scalable storage format for numerical data, available in pandas using the PyTables library.\n",
    "- Parquet: Part of the Apache Hadoop ecosystem, a binary, columnar storage format that provides efficient data compression and encoding and has been developed by Cloudera and Twitter. It is available for pandas through the `pyarrow` library, led by Wes McKinney, the original author of pandas.\n",
    "\n",
    "This notebook compares the performance of the preceding libraries using a test DataFrame that can be configured to contain numerical or text data, or both. For the HDF5 library, we test both the fixed and table formats. The table format allows for queries and can be appended to.\n",
    "\n",
    "## Usage\n",
    "\n",
    "To recreate the charts used in the book, you need to run this notebook twice up to section 'Store Result' using different settings for `data_type` and arguments for `generate_test_data` as follows:\n",
    "1. `data_type='Numeric`: `numerical_cols=2000`, `text_cols=0` (default)\n",
    "2. `data_type='Mixed`: `numerical_cols=1000`, `text_cols=1000`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:14:05.252103Z",
     "start_time": "2024-01-24T19:14:05.235543Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:14:05.258015Z",
     "start_time": "2024-01-24T19:14:05.243820Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:14:05.279258Z",
     "start_time": "2024-01-24T19:14:05.250844Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:14:05.351946Z",
     "start_time": "2024-01-24T19:14:05.260390Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test `DataFrame` that can be configured to contain numerical or text data, or both. For the HDF5 library, we test both the fixed and table format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:14:05.355313Z",
     "start_time": "2024-01-24T19:14:05.268886Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_test_data(nrows=100000, numerical_cols=2000, text_cols=0, text_length=10):\n",
    "    s = \"\".join([random.choice(string.ascii_letters)\n",
    "                 for _ in range(text_length)])\n",
    "    data = pd.concat([pd.DataFrame(np.random.random(size=(nrows, numerical_cols))),\n",
    "                      pd.DataFrame(np.full(shape=(nrows, text_cols), fill_value=s))],\n",
    "                     axis=1, ignore_index=True)\n",
    "    data.columns = [str(i) for i in data.columns]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:14:05.375503Z",
     "start_time": "2024-01-24T19:14:05.276985Z"
    }
   },
   "outputs": [],
   "source": [
    "data_type = 'Numeric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:16:18.161477Z",
     "start_time": "2024-01-24T19:14:05.284314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Columns: 2000 entries, 0 to 1999\n",
      "dtypes: float64(1000), object(1000)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df = generate_test_data(numerical_cols=1000, text_cols=1000)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:16:18.287627Z",
     "start_time": "2024-01-24T19:16:18.115182Z"
    }
   },
   "outputs": [],
   "source": [
    "parquet_file = Path('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:17:21.628441Z",
     "start_time": "2024-01-24T19:16:18.151765Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_parquet(parquet_file)\n",
    "size = parquet_file.stat().st_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:18:34.531174Z",
     "start_time": "2024-01-24T19:17:21.681522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.67 s ± 3.5 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<TimeitResult : 7.67 s ± 3.5 s per loop (mean ± std. dev. of 7 runs, 1 loop each)>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -o\n",
    "df = pd.read_parquet(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-01-24T19:18:34.543868Z",
     "start_time": "2024-01-24T19:18:34.539661Z"
    }
   },
   "outputs": [],
   "source": [
    "read = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:18:34.691571Z",
     "start_time": "2024-01-24T19:18:34.547569Z"
    }
   },
   "outputs": [],
   "source": [
    "parquet_file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:26:43.702260Z",
     "start_time": "2024-01-24T19:18:34.691671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.1 s ± 10 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<TimeitResult : 55.1 s ± 10 s per loop (mean ± std. dev. of 7 runs, 1 loop each)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -o\n",
    "df.to_parquet(parquet_file)\n",
    "parquet_file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:26:43.825443Z",
     "start_time": "2024-01-24T19:26:43.684594Z"
    }
   },
   "outputs": [],
   "source": [
    "write = _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:26:43.831739Z",
     "start_time": "2024-01-24T19:26:43.698254Z"
    }
   },
   "outputs": [],
   "source": [
    "results['Parquet'] = {'read': np.mean(read.all_runs), 'write': np.mean(write.all_runs), 'size': size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:26:43.855687Z",
     "start_time": "2024-01-24T19:26:43.700038Z"
    }
   },
   "outputs": [],
   "source": [
    "test_store = Path('index.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-24T19:30:05.563883Z",
     "start_time": "2024-01-24T19:26:43.717033Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(test_store) as store:\n",
    "    store.put('file', df)\n",
    "size = test_store.stat().st_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-24T19:30:05.586786Z"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -o\n",
    "with pd.HDFStore(test_store) as store:\n",
    "    store.get('file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "read = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test_store.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%timeit -o\n",
    "with pd.HDFStore(test_store) as store:\n",
    "    store.put('file', df)\n",
    "test_store.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "write = _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "results['HDF Fixed'] = {'read': np.mean(read.all_runs), 'write': np.mean(write.all_runs), 'size': size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(test_store) as store:\n",
    "    store.append('file', df, format='t')\n",
    "size = test_store.stat().st_size    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%timeit -o\n",
    "with pd.HDFStore(test_store) as store:\n",
    "    df = store.get('file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "read = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test_store.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `write` in table format does not work with text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%timeit -o\n",
    "with pd.HDFStore(test_store) as store:\n",
    "    store.append('file', df, format='t')\n",
    "test_store.unlink()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "write = _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "results['HDF Table'] = {'read': np.mean(read.all_runs), 'write': np.mean(write.all_runs), 'size': size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(test_store) as store:\n",
    "    store.append('file', df, format='t', data_columns=['company', 'form'])\n",
    "size = test_store.stat().st_size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "company = 'APPLE INC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with pd.HDFStore(test_store) as store:\n",
    "    s = store.get('file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "read = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test_store.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with pd.HDFStore(test_store) as store:\n",
    "    store.append('file', df, format='t', data_columns=['company', 'form'])\n",
    "test_store.unlink() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "write = _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "results['HDF Select'] = {'read': np.mean(read.all_runs), 'write': np.mean(write.all_runs), 'size': size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test_csv = Path('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(test_csv)\n",
    "test_csv.stat().st_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%timeit -o\n",
    "df = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "read = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "test_csv.unlink()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%timeit -o\n",
    "df.to_csv(test_csv)\n",
    "test_csv.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "write = _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "results['CSV'] = {'read': np.mean(read.all_runs), 'write': np.mean(write.all_runs), 'size': size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results).assign(Data=data_type).to_csv(f'{data_type}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the notebook twice as described above under `Usage` to create the two `csv` files with results for different test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv('Numeric.csv', index_col=0)\n",
    "      .append(pd.read_csv('Mixed.csv', index_col=0))\n",
    "      .rename(columns=str.capitalize))\n",
    "df.index.name='Storage'\n",
    "df = df.set_index('Data', append=True).unstack()\n",
    "df.Size /= 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(16, 4))\n",
    "for i, op in enumerate(['Read', 'Write', 'Size']):\n",
    "    flag= op in ['Read', 'Write']\n",
    "    df.loc[:, op].plot.barh(title=op, ax=axes[i], logx=flag)\n",
    "    if flag:\n",
    "        axes[i].set_xlabel('seconds (log scale)')\n",
    "    else:\n",
    "        axes[i].set_xlabel('GB')\n",
    "fig.tight_layout()\n",
    "fig.savefig('storage', dpi=300);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
