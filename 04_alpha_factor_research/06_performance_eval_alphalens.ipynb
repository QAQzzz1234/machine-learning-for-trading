{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating signal and noise â€“ how to use alphalens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantopian has open sourced the Python library, alphalens, for the performance analysis of predictive stock factors that integrates well with the backtesting library zipline and the portfolio performance and risk analysis library pyfolio that we will explore in the next chapter.\n",
    "alphalens facilitates the analysis of the predictive power of alpha factors concerning the:\n",
    "- Correlation of the signals with subsequent returns\n",
    "- Profitability of an equal or factor-weighted portfolio based on a (subset of) the signals\n",
    "- Turnover of factors to indicate the potential trading costs\n",
    "- Factor-performance during specific events\n",
    "- Breakdowns of the preceding by sector\n",
    "\n",
    "The analysis can be conducted using tearsheets or individual computations and plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This notebook requires the `conda` environment `backtest`. Please see the [installation instructions](../installation/README.md) for running the latest Docker image or alternative ways to set up your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T22:13:23.270213Z",
     "start_time": "2024-02-26T22:13:23.266088Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T22:13:27.367380Z",
     "start_time": "2024-02-26T22:13:26.779940Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "from alphalens.utils import get_clean_factor_and_forward_returns\n",
    "from alphalens.performance import *\n",
    "from alphalens.plotting import *\n",
    "from alphalens.tears import *\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-26T22:13:29.371122Z",
     "start_time": "2024-02-26T22:13:29.361107Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating forward returns and factor quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To utilize `alpahalens`, we need to provide signals for a universe of assets like those returned by the ranks of the MeanReversion factor, and the forward returns earned by investing in an asset for a given holding period. .\n",
    "\n",
    "> This notebook uses the file `single_factor.pickle` with the results generated in the notebook `single_factor_zipline.ipynb` in this directory.\n",
    "\n",
    "We will recover the prices from the `single_factor.pickle` file as follows (`factor_data` accordingly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T22:13:33.657615Z",
     "start_time": "2024-02-26T22:13:31.959576Z"
    }
   },
   "outputs": [],
   "source": [
    "performance = pd.read_pickle('single_factor.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T22:13:33.674720Z",
     "start_time": "2024-02-26T22:13:33.659297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 755 entries, 2015-01-02 21:00:00+00:00 to 2017-12-29 21:00:00+00:00\n",
      "Data columns (total 39 columns):\n",
      " #   Column                   Non-Null Count  Dtype              \n",
      "---  ------                   --------------  -----              \n",
      " 0   period_open              755 non-null    datetime64[ns, UTC]\n",
      " 1   period_close             755 non-null    datetime64[ns, UTC]\n",
      " 2   longs_count              755 non-null    int64              \n",
      " 3   shorts_count             755 non-null    int64              \n",
      " 4   returns                  755 non-null    float64            \n",
      " 5   long_value               755 non-null    float64            \n",
      " 6   starting_exposure        755 non-null    float64            \n",
      " 7   short_value              755 non-null    float64            \n",
      " 8   pnl                      755 non-null    float64            \n",
      " 9   long_exposure            755 non-null    float64            \n",
      " 10  capital_used             755 non-null    float64            \n",
      " 11  orders                   755 non-null    object             \n",
      " 12  transactions             755 non-null    object             \n",
      " 13  short_exposure           755 non-null    float64            \n",
      " 14  positions                755 non-null    object             \n",
      " 15  ending_exposure          755 non-null    float64            \n",
      " 16  gross_leverage           755 non-null    float64            \n",
      " 17  starting_value           755 non-null    float64            \n",
      " 18  net_leverage             755 non-null    float64            \n",
      " 19  ending_value             755 non-null    float64            \n",
      " 20  starting_cash            755 non-null    float64            \n",
      " 21  ending_cash              755 non-null    float64            \n",
      " 22  portfolio_value          755 non-null    float64            \n",
      " 23  trading_days             755 non-null    int64              \n",
      " 24  period_label             755 non-null    object             \n",
      " 25  algorithm_period_return  755 non-null    float64            \n",
      " 26  treasury_period_return   755 non-null    float64            \n",
      " 27  algo_volatility          754 non-null    float64            \n",
      " 28  benchmark_period_return  755 non-null    float64            \n",
      " 29  benchmark_volatility     754 non-null    float64            \n",
      " 30  max_leverage             755 non-null    float64            \n",
      " 31  alpha                    0 non-null      object             \n",
      " 32  beta                     0 non-null      object             \n",
      " 33  sharpe                   753 non-null    float64            \n",
      " 34  sortino                  753 non-null    float64            \n",
      " 35  max_drawdown             755 non-null    float64            \n",
      " 36  excess_return            755 non-null    float64            \n",
      " 37  factor_data              754 non-null    object             \n",
      " 38  prices                   754 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](2), float64(26), int64(3), object(8)\n",
      "memory usage: 235.9+ KB\n"
     ]
    }
   ],
   "source": [
    "performance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T22:13:37.343603Z",
     "start_time": "2024-02-26T22:13:37.066963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 754 entries, 2015-01-05 00:00:00+00:00 to 2017-12-29 00:00:00+00:00\n",
      "Columns: 1649 entries, A to NETE\n",
      "dtypes: float64(1649)\n",
      "memory usage: 9.5 MB\n"
     ]
    }
   ],
   "source": [
    "prices = pd.concat([df.to_frame(d) for d, df in performance.prices.dropna().items()],axis=1).T\n",
    "prices.columns = [re.findall(r\"\\[(.+)\\]\", str(col))[0] for col in prices.columns]\n",
    "prices.index = prices.index.normalize()\n",
    "prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T22:13:39.144299Z",
     "start_time": "2024-02-26T22:13:38.855643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "date                       asset\n2015-01-05 00:00:00+00:00  A        2707.0\n                           AAL       870.0\n                           AAP      1253.0\n                           AAPL     2977.0\n                           ABBV     2806.0\ndtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_data = pd.concat([df.to_frame(d) for d, df in performance.factor_data.dropna().items()],axis=1).T\n",
    "factor_data.columns = [re.findall(r\"\\[(.+)\\]\", str(col))[0] for col in factor_data.columns]\n",
    "factor_data.index = factor_data.index.normalize()\n",
    "factor_data = factor_data.stack()\n",
    "factor_data.index.names = ['date', 'asset']\n",
    "factor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-02-26T22:13:41.265635Z",
     "start_time": "2024-02-26T22:13:41.222068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Date\n2015-01-05 00:00:00+00:00    2020.58\n2015-01-06 00:00:00+00:00    2002.61\n2015-01-07 00:00:00+00:00    2025.90\n2015-01-08 00:00:00+00:00    2062.14\n2015-01-09 00:00:00+00:00    2044.81\nName: close, dtype: float64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pd.HDFStore('../data/assets.h5') as store:\n",
    "    sp500 = store['sp500/stooq'].close\n",
    "sp500 = sp500.resample('D').ffill().tz_localize('utc').filter(prices.index.get_level_values(0))\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create the alphalens input data in the required format using the `get_clean_factor_and_forward_returns` utility function that also returns the signal quartiles and the forward returns for the given holding periods:"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "date                       asset\n2015-01-05 00:00:00+00:00  A        2707.0\n                           AAL       870.0\n                           AAP      1253.0\n                           AAPL     2977.0\n                           ABBV     2806.0\ndtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T22:13:43.695281Z",
     "start_time": "2024-02-26T22:13:43.687115Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T22:21:13.760742Z",
     "start_time": "2024-02-26T22:21:13.756775Z"
    }
   },
   "outputs": [],
   "source": [
    "HOLDING_PERIODS = (5, 10, 21, 42)\n",
    "QUANTILES = 5"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m alphalens_data \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mget_clean_factor_and_forward_returns(factor\u001B[38;5;241m=\u001B[39mfactor_data,\n\u001B[1;32m      2\u001B[0m                                                       prices\u001B[38;5;241m=\u001B[39mprices,\n\u001B[1;32m      3\u001B[0m                                                       periods\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m10\u001B[39m),\n\u001B[1;32m      4\u001B[0m                                                       quantiles\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/alphalens/utils.py:827\u001B[0m, in \u001B[0;36mget_clean_factor_and_forward_returns\u001B[0;34m(factor, prices, groupby, binning_by_group, quantiles, bins, periods, filter_zscore, groupby_labels, max_loss, zero_aware, cumulative_returns)\u001B[0m\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_clean_factor_and_forward_returns\u001B[39m(factor,\n\u001B[1;32m    667\u001B[0m                                          prices,\n\u001B[1;32m    668\u001B[0m                                          groupby\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    676\u001B[0m                                          zero_aware\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    677\u001B[0m                                          cumulative_returns\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    678\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    679\u001B[0m \u001B[38;5;124;03m    Formats the factor data, pricing data, and group mappings into a DataFrame\u001B[39;00m\n\u001B[1;32m    680\u001B[0m \u001B[38;5;124;03m    that contains aligned MultiIndex indices of timestamp and asset. The\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    825\u001B[0m \u001B[38;5;124;03m        For use when forward returns are already available.\u001B[39;00m\n\u001B[1;32m    826\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 827\u001B[0m     forward_returns \u001B[38;5;241m=\u001B[39m compute_forward_returns(\n\u001B[1;32m    828\u001B[0m         factor,\n\u001B[1;32m    829\u001B[0m         prices,\n\u001B[1;32m    830\u001B[0m         periods,\n\u001B[1;32m    831\u001B[0m         filter_zscore,\n\u001B[1;32m    832\u001B[0m         cumulative_returns,\n\u001B[1;32m    833\u001B[0m     )\n\u001B[1;32m    835\u001B[0m     factor_data \u001B[38;5;241m=\u001B[39m get_clean_factor(factor, forward_returns, groupby\u001B[38;5;241m=\u001B[39mgroupby,\n\u001B[1;32m    836\u001B[0m                                    groupby_labels\u001B[38;5;241m=\u001B[39mgroupby_labels,\n\u001B[1;32m    837\u001B[0m                                    quantiles\u001B[38;5;241m=\u001B[39mquantiles, bins\u001B[38;5;241m=\u001B[39mbins,\n\u001B[1;32m    838\u001B[0m                                    binning_by_group\u001B[38;5;241m=\u001B[39mbinning_by_group,\n\u001B[1;32m    839\u001B[0m                                    max_loss\u001B[38;5;241m=\u001B[39mmax_loss, zero_aware\u001B[38;5;241m=\u001B[39mzero_aware)\n\u001B[1;32m    841\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m factor_data\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/alphalens/utils.py:319\u001B[0m, in \u001B[0;36mcompute_forward_returns\u001B[0;34m(factor, prices, periods, filter_zscore, cumulative_returns)\u001B[0m\n\u001B[1;32m    316\u001B[0m     period_len \u001B[38;5;241m=\u001B[39m diff_custom_calendar_timedeltas(start, end, freq)\n\u001B[1;32m    317\u001B[0m     days_diffs\u001B[38;5;241m.\u001B[39mappend(period_len\u001B[38;5;241m.\u001B[39mcomponents\u001B[38;5;241m.\u001B[39mdays)\n\u001B[0;32m--> 319\u001B[0m delta_days \u001B[38;5;241m=\u001B[39m period_len\u001B[38;5;241m.\u001B[39mcomponents\u001B[38;5;241m.\u001B[39mdays \u001B[38;5;241m-\u001B[39m mode(days_diffs)\u001B[38;5;241m.\u001B[39mmode[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    320\u001B[0m period_len \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mTimedelta(days\u001B[38;5;241m=\u001B[39mdelta_days)\n\u001B[1;32m    321\u001B[0m label \u001B[38;5;241m=\u001B[39m timedelta_to_string(period_len)\n",
      "\u001B[0;31mIndexError\u001B[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "alphalens_data = utils.get_clean_factor_and_forward_returns(factor=factor_data,\n",
    "                                                      prices=prices,\n",
    "                                                      periods=(1,5,10),\n",
    "                                                      quantiles=5)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T22:22:01.550220Z",
     "start_time": "2024-02-26T22:22:01.424727Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `alphalens_data` `DataFrame` contains the returns on an investment in the given asset on a given date for the indicated holding period, as well as the factor value, that is, the asset's `MeanReversion` ranking on that date, and the corresponding quantile value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T17:27:19.888464Z",
     "start_time": "2024-01-26T17:27:19.778215Z"
    }
   },
   "outputs": [],
   "source": [
    "alphalens_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T17:27:19.783596Z"
    }
   },
   "outputs": [],
   "source": [
    "alphalens_data.reset_index().head().to_csv('factor_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward returns and the signal quantiles are the basis for evaluating the predictive power of the signal. Typically, a factor should deliver markedly different returns for distinct quantiles, such as negative returns for the bottom quintile of the factor values and positive returns for the top quantile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Tear Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T17:27:19.788994Z"
    }
   },
   "outputs": [],
   "source": [
    "create_summary_tear_sheet(alphalens_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive performance by factor quantiles -  Returns Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we would like to visualize the average period return by factor quantile. We can use the built-in function mean_return_by_quantile from the performance and plot_quantile_returns_bar from the plotting modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T17:27:19.794694Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_return_by_q, std_err = mean_return_by_quantile(alphalens_data)\n",
    "mean_return_by_q_norm = mean_return_by_q.apply(lambda x: x.add(1).pow(1/int(x.name[:-1])).sub(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Return by Holding Period and Quintile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a bar chart that breaks down the mean of the forward returns for the four different holding periods based on the quintile of the factor signal. As you can see, the bottom quintiles yielded markedly more negative results than the top quintiles, except for the longest holding period:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2024-01-26T17:27:19.799805Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_quantile_returns_bar(mean_return_by_q)\n",
    "plt.tight_layout()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10D holding period provides slightly better results for the first and fourth quartiles. We would also like to see the performance over time of investments driven by each of the signal quintiles. \n",
    "\n",
    "We will calculate daily, as opposed to average returns for the 5D holding period, and alphalens will adjust the period returns to account for the mismatch between daily signals and a longer holding period (for details, see docs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T17:27:19.805764Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_return_by_q_daily, std_err = mean_return_by_quantile(alphalens_data, by_date=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative 5D Return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting line plot shows that, for most of this three-year period, the top two quintiles significantly outperformed the bottom two quintiles. However, as suggested by the previous plot, signals by the fourth quintile produced a better performance than those by the top quintile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T17:27:19.812998Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cumulative_returns_by_quantile(mean_return_by_q_daily['5D'], period='5D', freq=None)\n",
    "plt.tight_layout()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Distribution by Holding Period and Quintile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distributional plot highlights that the range of daily returns is fairly wide and, despite different means, the separation of the distributions is very limited so that, on any given day, the differences in performance between the different quintiles may be rather limited:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T17:27:19.816427Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_quantile_returns_violin(mean_return_by_q_daily)\n",
    "plt.tight_layout()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of this book is about the design of alpha factors using ML models. ML is about optimizing some predictive objective, and in this section, we will introduce the key metrics used to measure the performance of an alpha factor. We will define alpha as the average return in excess of a benchmark.\n",
    "This leads to the information ratio (IR) that measures the average excess return per unit of risk taken by dividing alpha by the tracking risk. When the benchmark is the risk-free rate, the IR corresponds to the well-known Sharpe ratio, and we will highlight crucial statistical measurement issues that arise in the typical case when returns are not normally distributed. We will also explain the fundamental law of active management that breaks the IR down into a combination of forecasting skill and a strategy's ability to effectively leverage the forecasting skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5D Information Coefficient (Rolling Average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of alpha factors is the accurate directional prediction of future returns. Hence, a natural performance measure is the correlation between an alpha factor's predictions and the forward returns of the target assets. \n",
    "\n",
    "It is better to use the non-parametric Spearman rank correlation coefficient that measures how well the relationship between two variables can be described using a monotonic function, as opposed to the Pearson correlation that measures the strength of a linear relationship. \n",
    "\n",
    "We can obtain the information coefficient using alphalens, which relies on `scipy.stats.spearmanr` under the hood. \n",
    "\n",
    "The `factor_information_coefficient` function computes the period-wise correlation and plot_ic_ts creates a time-series plot with one-month moving average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T17:27:19.819630Z"
    }
   },
   "outputs": [],
   "source": [
    "ic = factor_information_coefficient(alphalens_data)\n",
    "plot_ic_ts(ic[['5D']])\n",
    "plt.tight_layout()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Coefficient by Holding Period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time series plot shows extended periods with significantly positive moving-average IC. An IC of 0.05 or even 0.1 allows for significant outperformance if there are sufficient opportunities to apply this forecasting skill, as the fundamental law of active management will illustrate:\n",
    "\n",
    "A plot of the annual mean IC highlights how the factor's performance was historically uneven:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-26T17:27:19.824256Z"
    }
   },
   "outputs": [],
   "source": [
    "ic = factor_information_coefficient(alphalens_data)\n",
    "ic_by_year = ic.resample('A').mean()\n",
    "ic_by_year.index = ic_by_year.index.year\n",
    "ic_by_year.plot.bar(figsize=(14, 6))\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turnover Tear Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor turnover measures how frequently the assets associated with a given quantile change, that is, how many trades are required to adjust a portfolio to the sequence of signals. More specifically, it measures the share of assets currently in a factor quantile that was not in that quantile in the last period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T17:27:19.827159Z"
    }
   },
   "outputs": [],
   "source": [
    "create_turnover_tear_sheet(alphalens_data);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.355px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
