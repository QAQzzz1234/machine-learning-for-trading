{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to transform data into factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on a conceptual understanding of key factor categories, their rationale and popular metrics, a key task is to identify new factors that may better capture the risks embodied by the return drivers laid out previously, or to find new ones. \n",
    "\n",
    "In either case, it will be important to compare the performance of innovative factors to that of known factors to identify incremental signal gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the dataset here and store it in our [data](../data) folder to facilitate reuse in later chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:08:14.077152Z",
     "start_time": "2024-01-24T19:08:14.073103Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:08:15.069991Z",
     "start_time": "2024-01-24T19:08:14.080684Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "# replaces pyfinance.ols.PandasRollingOLS (no longer maintained)\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:08:15.089071Z",
     "start_time": "2024-01-24T19:08:15.070239Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `assets.h5` store can be generated using the the notebook [create_datasets](../data/create_datasets.ipynb) in the [data](../data) directory in the root directory of this repo for instruction to download the following dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the Quandl stock price datasets covering the US equity markets 2000-18 using `pd.IndexSlice` to perform a slice operation on the `pd.MultiIndex`, select the adjusted close price and unpivot the column to convert the DataFrame to wide format with tickers in the columns and timestamps in the rows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data store location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:08:15.091066Z",
     "start_time": "2024-01-24T19:08:15.079048Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_STORE = '../data/assets.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:08:15.092835Z",
     "start_time": "2024-01-24T19:08:15.082795Z"
    }
   },
   "outputs": [],
   "source": [
    "START = 2000\n",
    "END = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:08:16.642052Z",
     "start_time": "2024-01-24T19:08:15.087539Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No object named quandl/wiki/prices in the file'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mHDFStore(DATA_STORE) \u001B[38;5;28;01mas\u001B[39;00m store:\n\u001B[0;32m----> 2\u001B[0m     prices \u001B[38;5;241m=\u001B[39m (store[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquandl/wiki/prices\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      3\u001B[0m               \u001B[38;5;241m.\u001B[39mloc[idx[\u001B[38;5;28mstr\u001B[39m(START):\u001B[38;5;28mstr\u001B[39m(END), :], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124madj_close\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      4\u001B[0m               \u001B[38;5;241m.\u001B[39munstack(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mticker\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      5\u001B[0m     stocks \u001B[38;5;241m=\u001B[39m store[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mus_equities/stocks\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mloc[:, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmarketcap\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mipoyear\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msector\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/pytables.py:596\u001B[0m, in \u001B[0;36mHDFStore.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key: \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m--> 596\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget(key)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/pytables.py:790\u001B[0m, in \u001B[0;36mHDFStore.get\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    788\u001B[0m group \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_node(key)\n\u001B[1;32m    789\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m group \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 790\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo object named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in the file\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    791\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_group(group)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'No object named quandl/wiki/prices in the file'"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    prices = (store['quandl/wiki/prices']\n",
    "              .loc[idx[str(START):str(END), :], 'adj_close']\n",
    "              .unstack('ticker'))\n",
    "    stocks = store['us_equities/stocks'].loc[:, ['marketcap', 'ipoyear', 'sector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T19:08:16.823708Z",
     "start_time": "2024-01-24T19:08:16.647441Z"
    }
   },
   "outputs": [],
   "source": [
    "prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.649891Z"
    }
   },
   "outputs": [],
   "source": [
    "stocks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep data with stock info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `stocks` duplicates and align index names for later joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.653313Z"
    }
   },
   "outputs": [],
   "source": [
    "stocks = stocks[~stocks.index.duplicated()]\n",
    "stocks.index.name = 'ticker'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tickers with both price information and metdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.655617Z"
    }
   },
   "outputs": [],
   "source": [
    "shared = prices.columns.intersection(stocks.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.658407Z"
    }
   },
   "outputs": [],
   "source": [
    "stocks = stocks.loc[shared, :]\n",
    "stocks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.662140Z"
    }
   },
   "outputs": [],
   "source": [
    "prices = prices.loc[:, shared]\n",
    "prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.667607Z"
    }
   },
   "outputs": [],
   "source": [
    "assert prices.shape[1] == stocks.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create monthly return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce training time and experiment with strategies for longer time horizons, we convert the business-daily data to month-end frequency using the available adjusted close price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.670533Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_prices = prices.resample('M').last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To capture time series dynamics that reflect, for example, momentum patterns, we compute historical returns using the method `.pct_change(n_periods)`, that is, returns over various monthly periods as identified by lags.\n",
    "\n",
    "We then convert the wide result back to long format with the `.stack()` method, use `.pipe()` to apply the `.clip()` method to the resulting `DataFrame`, and winsorize returns at the [1%, 99%] levels; that is, we cap outliers at these percentiles.\n",
    "\n",
    "Finally, we normalize returns using the geometric average. After using `.swaplevel()` to change the order of the `MultiIndex` levels, we obtain compounded monthly returns for six periods ranging from 1 to 12 months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.675763Z"
    }
   },
   "outputs": [],
   "source": [
    "monthly_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.679363Z"
    }
   },
   "outputs": [],
   "source": [
    "outlier_cutoff = 0.01\n",
    "data = pd.DataFrame()\n",
    "lags = [1, 2, 3, 6, 9, 12]\n",
    "for lag in lags:\n",
    "    data[f'return_{lag}m'] = (monthly_prices\n",
    "                           .pct_change(lag)\n",
    "                           .stack()\n",
    "                           .pipe(lambda x: x.clip(lower=x.quantile(outlier_cutoff),\n",
    "                                                  upper=x.quantile(1-outlier_cutoff)))\n",
    "                           .add(1)\n",
    "                           .pow(1/lag)\n",
    "                           .sub(1)\n",
    "                           )\n",
    "data = data.swaplevel().dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop stocks with less than 10 yrs of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.682544Z"
    }
   },
   "outputs": [],
   "source": [
    "min_obs = 120\n",
    "nobs = data.groupby(level='ticker').size()\n",
    "keep = nobs[nobs>min_obs].index\n",
    "\n",
    "data = data.loc[idx[keep,:], :]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.685422Z"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.687824Z"
    }
   },
   "outputs": [],
   "source": [
    "# cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "sns.clustermap(data.corr('spearman'), annot=True, center=0, cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are left with 1,670 tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.692074Z"
    }
   },
   "outputs": [],
   "source": [
    "data.index.get_level_values('ticker').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Factor Betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will introduce the Fama—French data to estimate the exposure of assets to common risk factors using linear regression in [Chapter 9, Time Series Models](../09_time_series_models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The five Fama—French factors, namely market risk, size, value, operating profitability, and investment have been shown empirically to explain asset returns and are commonly used to assess the risk/return profile of portfolios. Hence, it is natural to include past factor exposures as financial features in models that aim to predict future returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the historical factor returns using the `pandas-datareader` and estimate historical exposures using the `RollingOLS` rolling linear regression functionality in the `statsmodels` library as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Fama-French research factors to estimate the factor exposures of the stock in the dataset to the 5 factors market risk, size, value, operating profitability and investment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.694920Z"
    }
   },
   "outputs": [],
   "source": [
    "factors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
    "factor_data = web.DataReader('F-F_Research_Data_5_Factors_2x3', 'famafrench', start='2000')[0].drop('RF', axis=1)\n",
    "factor_data.index = factor_data.index.to_timestamp()\n",
    "factor_data = factor_data.resample('M').last().div(100)\n",
    "factor_data.index.name = 'date'\n",
    "factor_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.698143Z"
    }
   },
   "outputs": [],
   "source": [
    "factor_data = factor_data.join(data['return_1m']).sort_index()\n",
    "factor_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.700500Z"
    }
   },
   "outputs": [],
   "source": [
    "T = 24\n",
    "betas = (factor_data.groupby(level='ticker',\n",
    "                             group_keys=False)\n",
    "         .apply(lambda x: RollingOLS(endog=x.return_1m,\n",
    "                                     exog=sm.add_constant(x.drop('return_1m', axis=1)),\n",
    "                                     window=min(T, x.shape[0]-1))\n",
    "                .fit(params_only=True)\n",
    "                .params\n",
    "                .drop('const', axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.703165Z"
    }
   },
   "outputs": [],
   "source": [
    "betas.describe().join(betas.sum(1).describe().to_frame('total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.707465Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "sns.clustermap(betas.corr(), annot=True, cmap=cmap, center=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.712671Z"
    }
   },
   "outputs": [],
   "source": [
    "data = (data\n",
    "        .join(betas\n",
    "              .groupby(level='ticker')\n",
    "              .shift()))\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute mean for missing factor betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.715951Z"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[:, factors] = data.groupby('ticker')[factors].apply(lambda x: x.fillna(x.mean()))\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these results to compute momentum factors based on the difference between returns over longer periods and the most recent monthly return, as well as for the difference between 3 and 12 month returns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.718696Z"
    }
   },
   "outputs": [],
   "source": [
    "for lag in [2,3,6,9,12]:\n",
    "    data[f'momentum_{lag}'] = data[f'return_{lag}m'].sub(data.return_1m)\n",
    "data[f'momentum_3_12'] = data[f'return_12m'].sub(data.return_3m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.721308Z"
    }
   },
   "outputs": [],
   "source": [
    "dates = data.index.get_level_values('date')\n",
    "data['year'] = dates.year\n",
    "data['month'] = dates.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagged returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use lagged values as input variables or features associated with the current observations, we use the .shift() method to move historical returns up to the current period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.723925Z"
    }
   },
   "outputs": [],
   "source": [
    "for t in range(1, 7):\n",
    "    data[f'return_1m_t-{t}'] = data.groupby(level='ticker').return_1m.shift(t)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target: Holding Period Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, to compute returns for various holding periods, we use the normalized period returns computed previously and shift them back to align them with the current financial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.725748Z"
    }
   },
   "outputs": [],
   "source": [
    "for t in [1,2,3,6,12]:\n",
    "    data[f'target_{t}m'] = data.groupby(level='ticker')[f'return_{t}m'].shift(-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.728781Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['target_1m',\n",
    "        'target_2m',\n",
    "        'target_3m', \n",
    "        'return_1m',\n",
    "        'return_2m',\n",
    "        'return_3m',\n",
    "        'return_1m_t-1',\n",
    "        'return_1m_t-2',\n",
    "        'return_1m_t-3']\n",
    "\n",
    "data[cols].dropna().sort_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.732455Z"
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create age proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use quintiles of IPO year as a proxy for company age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.734211Z"
    }
   },
   "outputs": [],
   "source": [
    "data = (data\n",
    "        .join(pd.qcut(stocks.ipoyear, q=5, labels=list(range(1, 6)))\n",
    "              .astype(float)\n",
    "              .fillna(0)\n",
    "              .astype(int)\n",
    "              .to_frame('age')))\n",
    "data.age = data.age.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dynamic size proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the marketcap information from the NASDAQ ticker info to create a size proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.736385Z"
    }
   },
   "outputs": [],
   "source": [
    "stocks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Market cap information is tied to currrent prices. We create an adjustment factor to have the values reflect lower historical prices for each individual stock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.738109Z"
    }
   },
   "outputs": [],
   "source": [
    "size_factor = (monthly_prices\n",
    "               .loc[data.index.get_level_values('date').unique(),\n",
    "                    data.index.get_level_values('ticker').unique()]\n",
    "               .sort_index(ascending=False)\n",
    "               .pct_change()\n",
    "               .fillna(0)\n",
    "               .add(1)\n",
    "               .cumprod())\n",
    "size_factor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.740618Z"
    }
   },
   "outputs": [],
   "source": [
    "msize = (size_factor\n",
    "         .mul(stocks\n",
    "              .loc[size_factor.columns, 'marketcap'])).dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Size indicator as deciles per period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute size deciles per month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.743669Z"
    }
   },
   "outputs": [],
   "source": [
    "data['msize'] = (msize\n",
    "                 .apply(lambda x: pd.qcut(x, q=10, labels=list(range(1, 11)))\n",
    "                        .astype(int), axis=1)\n",
    "                 .stack()\n",
    "                 .swaplevel())\n",
    "data.msize = data.msize.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.745779Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.join(stocks[['sector']])\n",
    "data.sector = data.sector.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.747710Z"
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the data again in several later chapters, starting in [Chapter 7 on Linear Models](../07_linear_models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.749614Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('engineered_features', data.sort_index().loc[idx[:, :datetime(2018, 3, 1)], :])\n",
    "    print(store.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most models, we need to encode categorical variables as 'dummies' (one-hot encoding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T19:08:16.751335Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_data = pd.get_dummies(data,\n",
    "                            columns=['year','month', 'msize', 'age',  'sector'],\n",
    "                            prefix=['year','month', 'msize', 'age', ''],\n",
    "                            prefix_sep=['_', '_', '_', '_', ''])\n",
    "dummy_data = dummy_data.rename(columns={c:c.replace('.0', '') for c in dummy_data.columns})\n",
    "dummy_data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.355px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
